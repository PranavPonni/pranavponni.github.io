<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>TASA | Tactile Sensory Attenuation Research | Pranav Ponnivalavan</title>
<meta name="keywords" content="In-hand manipulation, Robotic Hands, Cognitive Robotics, Tactile Sensing">
<meta name="description" content="A research thesis on distinguishing self and external touch through tactile sensing for robotic in-hand manipulation.">
<meta name="author" content="Pranav Ponnivalavan">
<link rel="canonical" href="https://pranavponni.github.io/research/book1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.977eaf2e691fe9d6783238f3ea60f3c0affcf333092baaee887438624edc50f3.css" integrity="sha256-l36vLmkf6dZ4Mjjz6mDzwK/88zMJK6ruiHQ4Yk7cUPM=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://pranavponni.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://pranavponni.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://pranavponni.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://pranavponni.github.io/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://pranavponni.github.io/research/book1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:url" content="https://pranavponni.github.io/research/book1/">
  <meta property="og:site_name" content="Pranav Ponnivalavan">
  <meta property="og:title" content="HASA | Hand Sensory Attenuation Research">
  <meta property="og:description" content="A research thesis on distinguishing self and external touch through tactile sensing for robotic in-hand manipulation.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="research">
    <meta property="article:tag" content="In-Hand Manipulation">
    <meta property="article:tag" content="Robotic Hands">
    <meta property="article:tag" content="Cognitive Robotics">
    <meta property="article:tag" content="Tactile Sensing">
    <meta property="og:image" content="https://pranavponni.github.io/research/book1/hasalogo.jpg">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://pranavponni.github.io/research/book1/hasalogo.jpg">
<meta name="twitter:title" content="HASA | Hand Sensory Attenuation Research">
<meta name="twitter:description" content="A research thesis on distinguishing self and external touch through tactile sensing for robotic in-hand manipulation.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Current Research",
      "item": "https://pranavponni.github.io/research/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "HASA | Hand Sensory Attenuation Research",
      "item": "https://pranavponni.github.io/research/book1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "HASA | Hand Sensory Attenuation Research",
  "name": "HASA | Hand Sensory Attenuation Research",
  "description": "A research thesis on distinguishing self and external touch through tactile sensing for robotic in-hand manipulation.",
  "keywords": [
    "In-hand manipulation", "Robotic Hands", "Cognitive Robotics", "Tactile Sensing"
  ],
  "articleBody": "Description HASA (Hand Sensory Attenuation) is an undergraduate thesis project that investigates how robotic hands equipped with tactile sensors can distinguish between self-generated touch and external touch. This ability, inspired by human somatosensory processes such as sensory attenuation, enables more dexterous and reliable in-hand manipulation.\nThe project leverages the Allegro Hand paired with XELA tactile sensors and proposes a two-phase learning strategy:\nA self-touch learning phase to model the robot’s own tactile feedback A motion generation phase to predict future tactile outcomes based on actions This approach draws from concepts in cognitive robotics, such as the free-energy principle, to optimize tactile predictions and generate robust manipulation behaviors. The system is evaluated through experiments involving self-grasping and object interaction, with comparisons to baseline models lacking self-touch understanding.\nShort Description “This project introduces an elegant framework for enabling robots to distinguish self from environment – a crucial step toward embodied intelligence.”\nSelf-Touch and Sensory Attenuation In humans, sensory attenuation reduces the perception of self-generated stimuli — this mechanism helps differentiate between one’s own actions and external influences. By modeling this concept in robotic systems, we enable the robot to predict and downweight expected tactile feedback resulting from its own movements.\nMathematical Model The robot learns the following mapping function:\n$\\hat{T}{t+1} = f(J_t,\\ J{t+1},\\ T_t)$\nWhere:\n$\\hat{T}_{t+1}$: predicted tactile state at time step $t+1$ $J_t,\\ J_{t+1}$: current and future joint states $T_t$: current tactile sensor input The model is trained to minimize the following loss function:\n$L = |T_{t+1} - \\hat{T}_{t+1}|^2$\nThis loss encourages the system to accurately predict tactile outcomes based on its motion, enabling it to distinguish between self-generated and externally generated touch.\nGallery Below are a few selected visuals from the HASA project demonstrating the hardware setup, data collection process, and tactile signal responses.\nFig 1: Allegro Hand and Tactile Sensor Setup\nFig 2: Difficulty of Task\nDemonstration Video Here is a demonstration of the HASA system performing mechanical pencil lead insertion task:\nYour browser does not support the video tag. Video 1: Self vs external touch prediction during in-hand manipulation.\nCitation Pranav Ponnivalavan. 2025. Hand Sensory Attenuation (HASA): Differentiating Self and External Touch for Robotic In-hand Manipulation. Waseda University, Tokyo, Japan.\n",
  "wordCount" : "362",
  "inLanguage": "en",
  "image":"https://pranavponni.github.io/research/book1/hasalogo.jpg","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Pranav Ponnivalavan"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://pranavponni.github.io/research/book1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Pranav Ponnivalavan",
    "logo": {
      "@type": "ImageObject",
      "url": "https://pranavponni.github.io/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://pranavponni.github.io/" accesskey="h" title="pranavponnivalavan">
                <img src="https://pranavponni.github.io/hand.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">pranavponnivalavan</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://pranavponni.github.io/research/" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://pranavponni.github.io/cv/" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="https://pranavponni.github.io/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      HASA | Hand Sensory Attenuation Research
    </h1>
    <div class="post-meta">Pranav Ponnivalavan

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#description">Description</a></li>
    <li><a href="#short-description">Short Description</a></li>
    <li><a href="#gallery">Gallery</a></li>
    <li><a href="#demonstration-video">Demonstration Video</a></li>
    <li><a href="#citation">Citation</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="description">Description<a hidden class="anchor" aria-hidden="true" href="#description">#</a></h2>
<p><strong>HASA</strong> (Hand Sensory Attenuation) is an undergraduate thesis project that investigates how robotic hands equipped with tactile sensors can distinguish between <em>self-generated touch</em> and <em>external touch</em>. This ability, inspired by human somatosensory processes such as sensory attenuation, enables more dexterous and reliable in-hand manipulation.</p>
<p>The project leverages the Allegro Hand paired with XELA tactile sensors and proposes a two-phase learning strategy:</p>
<ul>
<li>A <strong>self-touch learning phase</strong> to model the robot’s own tactile feedback</li>
<li>A <strong>motion generation phase</strong> to predict future tactile outcomes based on actions</li>
</ul>
<p>This approach draws from concepts in cognitive robotics, such as the <strong>free-energy principle</strong>, to optimize tactile predictions and generate robust manipulation behaviors. The system is evaluated through experiments involving self-grasping and object interaction, with comparisons to baseline models lacking self-touch understanding.</p>
<hr>
<h2 id="short-description">Short Description<a hidden class="anchor" aria-hidden="true" href="#short-description">#</a></h2>
<blockquote>
<p>&ldquo;This project introduces an elegant framework for enabling robots to distinguish self from environment – a crucial step toward embodied intelligence.&rdquo;</p></blockquote>
<hr>
<h4 id="self-touch-and-sensory-attenuation">Self-Touch and Sensory Attenuation<a hidden class="anchor" aria-hidden="true" href="#self-touch-and-sensory-attenuation">#</a></h4>
<p>In humans, <strong>sensory attenuation</strong> reduces the perception of self-generated stimuli — this mechanism helps differentiate between one’s own actions and external influences. By modeling this concept in robotic systems, we enable the robot to predict and downweight expected tactile feedback resulting from its own movements.</p>
<h4 id="mathematical-model">Mathematical Model<a hidden class="anchor" aria-hidden="true" href="#mathematical-model">#</a></h4>
<p>The robot learns the following mapping function:</p>
<p>$\hat{T}<em>{t+1} = f(J_t,\ J</em>{t+1},\ T_t)$</p>
<p>Where:</p>
<ul>
<li>$\hat{T}_{t+1}$: predicted tactile state at time step $t+1$</li>
<li>$J_t,\ J_{t+1}$: current and future joint states</li>
<li>$T_t$: current tactile sensor input</li>
</ul>
<hr>
<p>The model is trained to minimize the following loss function:</p>
<p>$L = |T_{t+1} - \hat{T}_{t+1}|^2$</p>
<p>This loss encourages the system to accurately predict tactile outcomes based on its motion, enabling it to <strong>distinguish between self-generated and externally generated touch</strong>.</p>
<hr>
<h2 id="gallery">Gallery<a hidden class="anchor" aria-hidden="true" href="#gallery">#</a></h2>
<p>Below are a few selected visuals from the <strong>HASA</strong> project demonstrating the hardware setup, data collection process, and tactile signal responses.</p>
<div style="display: flex; flex-wrap: wrap; gap: 1rem;">
  <img src="/view.png" alt="Allegro Hand and Tactile Sensor Setup" width="100%">
</div>
<blockquote>
<p><em>Fig 1</em>: Allegro Hand and Tactile Sensor Setup</p></blockquote>
<div style="display: flex; flex-wrap: wrap; gap: 1rem;">
  <img src="/diff.png" alt="Difficulty of Task" width="100%">
</div>
<blockquote>
<p><em>Fig 2</em>: Difficulty of Task</p></blockquote>
<hr>
<h2 id="demonstration-video">Demonstration Video<a hidden class="anchor" aria-hidden="true" href="#demonstration-video">#</a></h2>
<p>Here is a demonstration of the <strong>HASA</strong> system performing mechanical pencil lead insertion task:</p>
<video controls width="100%" style="border-radius: 12px;">
  <source src="/episode_video-3.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
<blockquote>
<p><em>Video 1</em>: Self vs external touch prediction during in-hand manipulation.</p></blockquote>
<hr>
<h2 id="citation">Citation<a hidden class="anchor" aria-hidden="true" href="#citation">#</a></h2>
<p>Pranav Ponnivalavan. 2025. <em>Hand Sensory Attenuation (HASA): Differentiating Self and External Touch for Robotic In-hand Manipulation</em>. Waseda University, Tokyo, Japan.</p>
<!-- ```bibtex
@bachelorsthesis{Ponnivalavan2025,
  author       = {Pranav Ponnivalavan},
  title        = {Hand Sensory Attenuation (HASA): Differentiating Self and External Touch for Robotic In-hand Manipulation},
  school       = {Waseda University},
  year         = {2025},
  address      = {Tokyo, Japan},
} -->


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://pranavponni.github.io/tags/in-hand-manipulation/">In-Hand Manipulation</a></li>
      <li><a href="https://pranavponni.github.io/tags/robotic-hands/">Robotic Hands</a></li>
      <li><a href="https://pranavponni.github.io/tags/cognitive-robotics/">Cognitive Robotics</a></li>
      <li><a href="https://pranavponni.github.io/tags/tactile-sensing/">Tactile Sensing</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 Pranav Ponnivalavan</span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">hugo</a>, <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">papermod</a>, &amp;
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">hugo-website</a>.
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
